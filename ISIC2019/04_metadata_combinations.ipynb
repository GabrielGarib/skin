{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cPRIevMl_fb"
   },
   "source": [
    "# ISIC2019\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GI_c_upDmXoH"
   },
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Yhc3LdzuYghn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import gc\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 7]\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import torchextractor as tx\n",
    "\n",
    "from itertools import chain, combinations\n",
    "\n",
    "def get_combs(l):\n",
    "    return list(chain.from_iterable(combinations(l, r) for r in range(1, len(l)+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "\n",
    "from utils.train import train\n",
    "from utils.metrics import get_scores, get_metrics\n",
    "from utils.dataset import get_data_loader\n",
    "from utils.models import get_model, BaseMetaModel, MetaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H586hAq5mb1b"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "g_dhCTuCZT6r",
    "outputId": "861f1cc4-b605-4625-bbeb-935eb4659edb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>diagnostic</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>anterior_torso</th>\n",
       "      <th>head_neck</th>\n",
       "      <th>lateral_torso</th>\n",
       "      <th>lower_extremity</th>\n",
       "      <th>oral_genital</th>\n",
       "      <th>palms_soles</th>\n",
       "      <th>posterior_torso</th>\n",
       "      <th>upper_extremity</th>\n",
       "      <th>diagnostic_number</th>\n",
       "      <th>folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0000000</td>\n",
       "      <td>NV</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0000001</td>\n",
       "      <td>NV</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0000002</td>\n",
       "      <td>MEL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0000003</td>\n",
       "      <td>NV</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0000004</td>\n",
       "      <td>MEL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25326</th>\n",
       "      <td>ISIC_0073247</td>\n",
       "      <td>BCC</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25327</th>\n",
       "      <td>ISIC_0073248</td>\n",
       "      <td>BKL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25328</th>\n",
       "      <td>ISIC_0073249</td>\n",
       "      <td>MEL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25329</th>\n",
       "      <td>ISIC_0073251</td>\n",
       "      <td>NV</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25330</th>\n",
       "      <td>ISIC_0073254</td>\n",
       "      <td>BKL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25331 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              image diagnostic  age_approx  female  male  anterior_torso  \\\n",
       "0      ISIC_0000000         NV        55.0       1     0               1   \n",
       "1      ISIC_0000001         NV        30.0       1     0               1   \n",
       "2      ISIC_0000002        MEL        60.0       1     0               0   \n",
       "3      ISIC_0000003         NV        30.0       0     1               0   \n",
       "4      ISIC_0000004        MEL        80.0       0     1               0   \n",
       "...             ...        ...         ...     ...   ...             ...   \n",
       "25326  ISIC_0073247        BCC        85.0       1     0               0   \n",
       "25327  ISIC_0073248        BKL        65.0       0     1               1   \n",
       "25328  ISIC_0073249        MEL        70.0       0     1               0   \n",
       "25329  ISIC_0073251         NV        55.0       1     0               0   \n",
       "25330  ISIC_0073254        BKL        50.0       0     1               0   \n",
       "\n",
       "       head_neck  lateral_torso  lower_extremity  oral_genital  palms_soles  \\\n",
       "0              0              0                0             0            0   \n",
       "1              0              0                0             0            0   \n",
       "2              0              0                0             0            0   \n",
       "3              0              0                0             0            0   \n",
       "4              0              0                0             0            0   \n",
       "...          ...            ...              ...           ...          ...   \n",
       "25326          1              0                0             0            0   \n",
       "25327          0              0                0             0            0   \n",
       "25328          0              0                1             0            0   \n",
       "25329          0              0                0             0            1   \n",
       "25330          0              0                0             0            0   \n",
       "\n",
       "       posterior_torso  upper_extremity  diagnostic_number  folder  \n",
       "0                    0                0                  5       0  \n",
       "1                    0                0                  5       1  \n",
       "2                    0                1                  4       2  \n",
       "3                    0                1                  5       3  \n",
       "4                    1                0                  4       4  \n",
       "...                ...              ...                ...     ...  \n",
       "25326                0                0                  1      26  \n",
       "25327                0                0                  2      27  \n",
       "25328                0                0                  4      28  \n",
       "25329                0                0                  5      29  \n",
       "25330                0                1                  2      30  \n",
       "\n",
       "[25331 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_metadata.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image', 'diagnostic', 'age_approx', 'female', 'male', 'anterior_torso',\n",
       "       'head_neck', 'lateral_torso', 'lower_extremity', 'oral_genital',\n",
       "       'palms_soles', 'posterior_torso', 'upper_extremity',\n",
       "       'diagnostic_number', 'folder'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4H_ZuBDtm-z9",
    "outputId": "8a79b0ab-82ce-4792-f021-b0e9e6155ad6"
   },
   "outputs": [],
   "source": [
    "open_file = open('train_idcs', \"rb\")\n",
    "train_folds = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "open_file = open('val_idcs', \"rb\")\n",
    "val_folds = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "open_file = open('test_idcs', \"rb\")\n",
    "test_idcs = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metacols_dict = {meta_type: [col  for prefix in meta_types_dict[meta_type] for col in df.columns if col.startswith(prefix)] for meta_type in  ['history', 'habits', 'lesion']}\n",
    "# metacols_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metacols_dict = {prefix: [col for col in df.columns if col.startswith(prefix)] for prefix in meta_prefixes}\n",
    "# #metacols_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "usemeta = ['age', 'gender', 'region']\n",
    "metacols_dict = {'age': ['age_approx'], 'gender': ['female', 'male'], 'region': ['anterior_torso',\n",
    "       'head_neck', 'lateral_torso', 'lower_extremity', 'oral_genital',\n",
    "       'palms_soles', 'posterior_torso', 'upper_extremity']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metacombs = get_combs(usemeta)\n",
    "len(metacombs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('age',): ['age_approx'],\n",
       " ('gender',): ['female', 'male'],\n",
       " ('region',): ['anterior_torso',\n",
       "  'head_neck',\n",
       "  'lateral_torso',\n",
       "  'lower_extremity',\n",
       "  'oral_genital',\n",
       "  'palms_soles',\n",
       "  'posterior_torso',\n",
       "  'upper_extremity'],\n",
       " ('age', 'gender'): ['age_approx', 'female', 'male'],\n",
       " ('age', 'region'): ['age_approx',\n",
       "  'anterior_torso',\n",
       "  'head_neck',\n",
       "  'lateral_torso',\n",
       "  'lower_extremity',\n",
       "  'oral_genital',\n",
       "  'palms_soles',\n",
       "  'posterior_torso',\n",
       "  'upper_extremity'],\n",
       " ('gender', 'region'): ['female',\n",
       "  'male',\n",
       "  'anterior_torso',\n",
       "  'head_neck',\n",
       "  'lateral_torso',\n",
       "  'lower_extremity',\n",
       "  'oral_genital',\n",
       "  'palms_soles',\n",
       "  'posterior_torso',\n",
       "  'upper_extremity'],\n",
       " ('age', 'gender', 'region'): ['age_approx',\n",
       "  'female',\n",
       "  'male',\n",
       "  'anterior_torso',\n",
       "  'head_neck',\n",
       "  'lateral_torso',\n",
       "  'lower_extremity',\n",
       "  'oral_genital',\n",
       "  'palms_soles',\n",
       "  'posterior_torso',\n",
       "  'upper_extremity']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combcols_dict = {comb: [col for meta in comb for col in metacols_dict[meta]] for comb in metacombs}\n",
    "combcols_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_names = ['resnet18']\n",
    "model_names = ['resnet50', 'effnetb3', 'resnext50', 'vgg11', 'vit_b_32']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fusion_methods = ['concat', 'metanet', 'metablock']\n",
    "fusion_methods = ['concat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir      = 'imgs/ISIC_2019_Training_Input'\n",
    "# batch_size    = 16\n",
    "batch_size    = 32\n",
    "\n",
    "num_workers   = 16\n",
    "input_size    = 224\n",
    "\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(input_size),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "val_transform   = transforms.Compose([transforms.Resize((input_size, input_size)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#n_classes = len(set(train_labels))\n",
    "n_epochs  = 100\n",
    "\n",
    "\n",
    "lr        = 1e-3 # Learning rate\n",
    "device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "n_samples = df.diagnostic_number.value_counts().sort_index().values\n",
    "\n",
    "weights = [1 - (x / sum(n_samples)) for x in n_samples]\n",
    "weights = torch.FloatTensor(weights).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=weights).to(device)\n",
    "\n",
    "saved_models_folder      = 'saved_comb_models'\n",
    "saved_scores_folder      = 'saved_comb_scores'\n",
    "saved_base_models_folder = 'saved_basemodels'\n",
    "saved_base_scores_folder = 'saved_basescores'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training modelos concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************************************\n",
      "RESNET50 AGE FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.8891       1.0687       0.7260      0.7392            1.0e-03       0.5\n",
      "    20      0.6410       0.9605       0.7891      0.7493            1.0e-04       0.5\n",
      "    30      0.6424       0.9200       0.7895      0.7526     ***    1.0e-04       0.5\n",
      "    40      0.6229       0.9056       0.7919      0.7498     ***    1.0e-05       0.5\n",
      "    50      0.6170       0.9111       0.7943      0.7438            1.0e-05       0.5\n",
      "    60      0.6193       0.9086       0.7960      0.7416            1.0e-05       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 67 Epochs: 34.3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "*****************************************************************************************\n",
      "EFFNETB3 AGE FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.7011       0.9606       0.7744      0.7226     ***    1.0e-04       0.5\n",
      "    20      0.6659       0.9270       0.7789      0.7303            1.0e-04       0.5\n",
      "    30      0.6670       0.9377       0.7754      0.7286            1.0e-04       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 39 Epochs: 20.3\n",
      "*****************************************************************************************\n",
      "RESNEXT50 AGE FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.7828       1.2593       0.7591      0.7103            1.0e-03       0.5\n",
      "    20      0.5815       0.9653       0.8094      0.7368     ***    1.0e-04       0.5\n",
      "    30      0.5709       0.9546       0.8151      0.7435     ***    1.0e-04       0.5\n",
      "    40      0.5555       0.9571       0.8154      0.7389            1.0e-05       0.5\n",
      "    50      0.5564       0.9689       0.8136      0.7356            1.0e-05       0.5\n",
      "    60      0.5495       0.9351       0.8169      0.7368     ***    1.0e-06       0.5\n",
      "    70      0.5572       0.9685       0.8176      0.7370            1.0e-07       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 75 Epochs: 38.9\n",
      "*****************************************************************************************\n",
      "VGG11 AGE FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.9219       1.2031       0.7217      0.6625            1.0e-03       0.5\n",
      "    20      0.6862       0.9367       0.7760      0.7248     ***    1.0e-04       0.6\n",
      "    30      0.6663       0.9378       0.7815      0.7231            1.0e-04       0.5\n",
      "    40      0.6396       0.9288       0.7883      0.7190            1.0e-05       0.5\n",
      "    50      0.6443       0.9408       0.7871      0.7135            1.0e-05       0.5\n",
      "    60      0.6520       0.9329       0.7832      0.7132            1.0e-06       0.5\n",
      "    70      0.6477       0.9334       0.7905      0.7185            1.0e-07       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 70 Epochs: 36.2\n",
      "*****************************************************************************************\n",
      "VIT_B_32 AGE FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      1.0619       1.4666       0.6774      0.6673            1.0e-03       0.5\n",
      "    20      1.0480       1.0786       0.6870      0.6678            1.0e-03       0.5\n",
      "    30      0.7450       0.9416       0.7507      0.7050     ***    1.0e-04       0.5\n",
      "    40      0.7206       0.9198       0.7528      0.6964            1.0e-04       0.5\n",
      "    50      0.7136       0.9282       0.7614      0.7024            1.0e-04       0.5\n",
      "    60      0.6965       0.9117       0.7643      0.7135            1.0e-04       0.5\n",
      "    70      0.6876       0.9043       0.7699      0.7125            1.0e-05       0.5\n",
      "    80      0.6791       0.9027       0.7711      0.7127            1.0e-06       0.5\n",
      "    90      0.6816       0.9072       0.7718      0.7123            1.0e-07       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 91 Epochs: 47.1\n",
      "*****************************************************************************************\n",
      "RESNET50 GENDER FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.7133       0.9029       0.7645      0.7346            1.0e-03       0.5\n",
      "    20      0.6632       0.9229       0.7783      0.7440            1.0e-04       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 29 Epochs: 14.9\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "*****************************************************************************************\n",
      "EFFNETB3 GENDER FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.6795       0.8963       0.7782      0.7168            1.0e-03       0.5\n",
      "    20      0.6625       0.9065       0.7803      0.7260            1.0e-04       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 22 Epochs: 11.5\n",
      "*****************************************************************************************\n",
      "RESNEXT50 GENDER FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.6225       0.9411       0.7928      0.7351            1.0e-03       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 17 Epochs: 8.8\n",
      "*****************************************************************************************\n",
      "VGG11 GENDER FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.7384       0.9294       0.7560      0.7082            1.0e-03       0.5\n",
      "    20      0.6951       0.9305       0.7712      0.7125            1.0e-04       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 21 Epochs: 10.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************************************\n",
      "VIT_B_32 GENDER FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.8715       0.9519       0.7137      0.6865     ***    1.0e-03       0.5\n",
      "    20      0.8063       0.9525       0.7346      0.6909            1.0e-03       0.5\n",
      "    30      0.7571       0.9213       0.7445      0.6957     ***    1.0e-04       0.6\n",
      "    40      0.7386       0.9273       0.7557      0.6988            1.0e-05       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 45 Epochs: 23.5\n",
      "*****************************************************************************************\n",
      "RESNET50 REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.7066       0.8997       0.7638      0.7435            1.0e-03       0.5\n",
      "    20      0.6445       0.9275       0.7849      0.7385            1.0e-04       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 22 Epochs: 11.3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "*****************************************************************************************\n",
      "EFFNETB3 REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.6935       0.8956       0.7708      0.7325            1.0e-03       0.5\n",
      "    20      0.6718       0.9031       0.7799      0.7245            1.0e-04       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 20 Epochs: 10.4\n",
      "*****************************************************************************************\n",
      "RESNEXT50 REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.6100       0.9205       0.7945      0.7346            1.0e-04       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 16 Epochs: 8.3\n",
      "*****************************************************************************************\n",
      "VGG11 REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.7389       0.9427       0.7572      0.7082            1.0e-03       0.5\n",
      "    20      0.6832       0.9270       0.7715      0.7108            1.0e-04       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 22 Epochs: 11.5\n",
      "*****************************************************************************************\n",
      "VIT_B_32 REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.8521       0.9468       0.7211      0.6868            1.0e-03       0.5\n",
      "    20      0.7777       0.9391       0.7393      0.7038            1.0e-03       0.5\n",
      "    30      0.7465       0.9299       0.7517      0.7043            1.0e-03       0.5\n",
      "    40      0.6929       0.9214       0.7650      0.7029            1.0e-04       0.5\n",
      "    50      0.6903       0.9093       0.7719      0.7043            1.0e-04       0.5\n",
      "    60      0.6887       0.9299       0.7700      0.7029            1.0e-05       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 66 Epochs: 34.2\n",
      "*****************************************************************************************\n",
      "RESNET50 AGE_GENDER FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.7176       0.9268       0.7702      0.7413     ***    1.0e-04       0.5\n",
      "    20      0.6727       0.9129       0.7786      0.7522            1.0e-04       0.5\n",
      "    30      0.6564       0.8999       0.7841      0.7401            1.0e-04       0.5\n",
      "    40      0.6356       0.8914       0.7895      0.7524            1.0e-05       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 42 Epochs: 21.6\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "*****************************************************************************************\n",
      "EFFNETB3 AGE_GENDER FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.8692       1.2280       0.7360      0.6930            1.0e-03       0.5\n",
      "    20      0.6603       0.9968       0.7802      0.7236            1.0e-04       0.5\n",
      "    30      0.6476       0.9242       0.7878      0.7192            1.0e-04       0.5\n",
      "    40      0.6403       0.9240       0.7873      0.7269            1.0e-04       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 47 Epochs: 24.6\n",
      "*****************************************************************************************\n",
      "RESNEXT50 AGE_GENDER FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.8148       1.3078       0.7619      0.7349            1.0e-03       0.5\n",
      "    20      0.5744       0.9808       0.8123      0.7327            1.0e-04       0.5\n",
      "    30      0.5693       0.9681       0.8097      0.7365            1.0e-04       0.5\n",
      "    40      0.5483       0.9521       0.8155      0.7373            1.0e-05       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 49 Epochs: 25.5\n",
      "*****************************************************************************************\n",
      "VGG11 AGE_GENDER FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.8980       1.1213       0.7255      0.6952            1.0e-03       0.5\n",
      "    20      0.6902       0.9397       0.7707      0.7238     ***    1.0e-04       0.6\n",
      "    30      0.6829       0.9564       0.7751      0.6962            1.0e-04       0.5\n",
      "    40      0.6624       0.9403       0.7789      0.7267            1.0e-04       0.5\n",
      "    50      0.6467       0.9177       0.7867      0.7231            1.0e-05       0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    60      0.6490       0.9252       0.7835      0.7178            1.0e-06       0.5\n",
      "    70      0.6537       0.9253       0.7831      0.7233            1.0e-06       0.5\n",
      "    80      0.6404       0.9199       0.7897      0.7178            1.0e-07       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 80 Epochs: 41.6\n",
      "*****************************************************************************************\n",
      "VIT_B_32 AGE_GENDER FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      1.0879       1.2030       0.6725      0.6036            1.0e-03       0.5\n",
      "    20      0.7814       0.9315       0.7431      0.7036     ***    1.0e-04       0.5\n",
      "    30      0.7591       0.9192       0.7465      0.6976            1.0e-04       0.5\n",
      "    40      0.7396       0.8995       0.7561      0.7096     ***    1.0e-05       0.5\n",
      "    50      0.7418       0.9057       0.7535      0.7038            1.0e-05       0.5\n",
      "    60      0.7315       0.8954       0.7591      0.7101            1.0e-06       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 68 Epochs: 35.2\n",
      "*****************************************************************************************\n",
      "RESNET50 AGE_REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.8917       1.1710       0.7325      0.6832            1.0e-03       0.5\n",
      "    20      0.6628       0.9663       0.7814      0.7495            1.0e-04       0.5\n",
      "    30      0.6291       0.9110       0.7926      0.7476            1.0e-05       0.5\n",
      "    40      0.6282       0.9071       0.7938      0.7370            1.0e-05       0.5\n",
      "    50      0.6162       0.8986       0.7975      0.7498     ***    1.0e-06       0.5\n",
      "    60      0.6309       0.9067       0.7922      0.7478            1.0e-07       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 65 Epochs: 33.5\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "*****************************************************************************************\n",
      "EFFNETB3 AGE_REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.8538       1.0494       0.7467      0.6954     ***    1.0e-03       0.5\n",
      "    20      0.6507       0.9872       0.7885      0.7221            1.0e-04       0.5\n",
      "    30      0.6290       0.9113       0.7910      0.7286            1.0e-04       0.5\n",
      "    40      0.6069       0.9065       0.8011      0.7320            1.0e-05       0.5\n",
      "    50      0.6199       0.9079       0.7962      0.7322            1.0e-05       0.5\n",
      "    60      0.6120       0.9019       0.7962      0.7361            1.0e-06       0.5\n",
      "    70      0.6168       0.8931       0.7974      0.7327            1.0e-07       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 71 Epochs: 37.0\n",
      "*****************************************************************************************\n",
      "RESNEXT50 AGE_REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.6253       0.9829       0.7993      0.7375     ***    1.0e-04       0.5\n",
      "    20      0.5727       0.9476       0.8095      0.7392            1.0e-04       0.5\n",
      "    30      0.5756       0.9160       0.8083      0.7411     ***    1.0e-04       0.5\n",
      "    40      0.5737       0.9326       0.8150      0.7409            1.0e-04       0.5\n",
      "    50      0.5656       0.9381       0.8102      0.7413            1.0e-05       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 50 Epochs: 26.2\n",
      "*****************************************************************************************\n",
      "VGG11 AGE_REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.7343       0.9445       0.7637      0.7180     ***    1.0e-04       0.6\n",
      "    20      0.6961       0.9122       0.7687      0.7209            1.0e-04       0.5\n",
      "    30      0.6849       0.9323       0.7744      0.7173            1.0e-04       0.5\n",
      "    40      0.6766       0.9079       0.7755      0.7125            1.0e-04       0.5\n",
      "    50      0.6645       0.9095       0.7830      0.7171            1.0e-05       0.5\n",
      "    60      0.6518       0.8993       0.7871      0.7185     ***    1.0e-05       0.6\n",
      "    70      0.6555       0.8929       0.7834      0.7219     ***    1.0e-05       0.6\n",
      "    80      0.6505       0.9117       0.7864      0.7147            1.0e-06       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 85 Epochs: 44.2\n",
      "*****************************************************************************************\n",
      "VIT_B_32 AGE_REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      1.0343       1.1616       0.6854      0.6344            1.0e-03       0.5\n",
      "    20      0.7823       0.9303       0.7410      0.7002            1.0e-04       0.5\n",
      "    30      0.7682       0.9193       0.7457      0.7183            1.0e-04       0.5\n",
      "    40      0.7329       0.9010       0.7573      0.7079            1.0e-05       0.5\n",
      "    50      0.7356       0.9021       0.7551      0.7063            1.0e-06       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 53 Epochs: 27.5\n",
      "*****************************************************************************************\n",
      "RESNET50 GENDER_REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.7060       0.9064       0.7664      0.7399            1.0e-03       0.5\n",
      "    20      0.6611       0.9123       0.7823      0.7440            1.0e-04       0.5\n",
      "    30      0.6571       0.9048       0.7828      0.7428            1.0e-05       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 32 Epochs: 16.5\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "*****************************************************************************************\n",
      "EFFNETB3 GENDER_REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.6771       0.8909       0.7755      0.7281            1.0e-03       0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 19 Epochs: 9.9\n",
      "*****************************************************************************************\n",
      "RESNEXT50 GENDER_REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.6133       0.9175       0.7966      0.7226            1.0e-03       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 17 Epochs: 8.8\n",
      "*****************************************************************************************\n",
      "VGG11 GENDER_REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.7279       0.9117       0.7604      0.7188            1.0e-03       0.5\n",
      "    20      0.6786       0.9198       0.7719      0.7180            1.0e-04       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 22 Epochs: 11.5\n",
      "*****************************************************************************************\n",
      "VIT_B_32 GENDER_REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.8578       0.9387       0.7175      0.6880            1.0e-03       0.5\n",
      "    20      0.7942       0.9233       0.7386      0.7043            1.0e-03       0.5\n",
      "    30      0.7454       0.9424       0.7489      0.7012            1.0e-03       0.5\n",
      "    40      0.7009       0.9233       0.7675      0.6998            1.0e-04       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 48 Epochs: 24.9\n",
      "*****************************************************************************************\n",
      "RESNET50 AGE_GENDER_REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.9099       1.2317       0.7250      0.7228            1.0e-03       0.5\n",
      "    20      0.6638       0.9372       0.7801      0.7531            1.0e-04       0.5\n",
      "    30      0.6446       0.9352       0.7818      0.7466            1.0e-04       0.5\n",
      "    40      0.6238       0.9309       0.7915      0.7498            1.0e-05       0.5\n",
      "    50      0.6203       0.9285       0.7925      0.7526            1.0e-06       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 53 Epochs: 27.4\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "*****************************************************************************************\n",
      "EFFNETB3 AGE_GENDER_REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.6916       0.9569       0.7774      0.7394            1.0e-04       0.5\n",
      "    20      0.6464       0.8959       0.7857      0.7337     ***    1.0e-04       0.5\n",
      "    30      0.6371       0.8930       0.7926      0.7349     ***    1.0e-05       0.5\n",
      "    40      0.6273       0.8946       0.7940      0.7329            1.0e-05       0.5\n",
      "    50      0.6376       0.8801       0.7905      0.7375            1.0e-05       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 58 Epochs: 30.3\n",
      "*****************************************************************************************\n",
      "RESNEXT50 AGE_GENDER_REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.8045       1.0341       0.7610      0.7346            1.0e-03       0.5\n",
      "    20      0.5666       0.9948       0.8141      0.7257     ***    1.0e-04       0.5\n",
      "    30      0.5557       1.0012       0.8187      0.7315            1.0e-04       0.5\n",
      "    40      0.5467       0.9574       0.8203      0.7404            1.0e-05       0.5\n",
      "    50      0.5381       0.9416       0.8223      0.7413            1.0e-06       0.5\n",
      "    60      0.5249       0.9558       0.8270      0.7373            1.0e-06       0.5\n",
      "    70      0.5339       0.9516       0.8218      0.7466            1.0e-07       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 71 Epochs: 37.0\n",
      "*****************************************************************************************\n",
      "VGG11 AGE_GENDER_REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      0.7298       0.9559       0.7614      0.7188     ***    1.0e-04       0.6\n",
      "    20      0.6944       0.9195       0.7679      0.7168            1.0e-04       0.5\n"
     ]
    }
   ],
   "source": [
    "#folds = [0, 1, 2, 3, 4]\n",
    "#folds = [1, 2, 3, 4]\n",
    "folds  = [0]\n",
    "n_reducer_block = 256\n",
    "\n",
    "for fold in folds:\n",
    "    for metacomb in metacombs:\n",
    "        metacomb_name = '_'.join(list(metacomb))\n",
    "        \n",
    "        metadata_cols = combcols_dict[metacomb]\n",
    "        \n",
    "         # Dataloaders\n",
    "        train_idcs = train_folds[fold]\n",
    "        val_idcs   = val_folds[fold]\n",
    "        train_imgs = df.loc[train_idcs, 'image'].values\n",
    "        val_imgs   = df.loc[val_idcs, 'image'].values\n",
    "        test_imgs  = df.loc[test_idcs, 'image'].values\n",
    "\n",
    "        train_paths = [f'{os.path.join(data_dir, img)}.jpg' for img in train_imgs]\n",
    "        val_paths   = [f'{os.path.join(data_dir, img)}.jpg' for img in val_imgs]\n",
    "        test_paths  = [f'{os.path.join(data_dir, img)}.jpg' for img in test_imgs]\n",
    "\n",
    "        train_labels = df.loc[train_idcs, 'diagnostic_number'].values\n",
    "        val_labels   = df.loc[val_idcs,   'diagnostic_number'].values\n",
    "        test_labels  = df.loc[test_idcs,  'diagnostic_number'].values\n",
    "\n",
    "        train_metadata = df.loc[train_idcs, metadata_cols].values\n",
    "        val_metadata   = df.loc[val_idcs, metadata_cols].values\n",
    "        test_metadata  = df.loc[test_idcs, metadata_cols].values\n",
    "        train_dataloader = get_data_loader(train_paths, train_labels, metadata=train_metadata, transform=train_transform, batch_size=batch_size, num_workers=num_workers)\n",
    "        val_dataloader   = get_data_loader(val_paths, val_labels, metadata=val_metadata, transform=val_transform, batch_size=batch_size, num_workers=num_workers)\n",
    "        test_dataloader  = get_data_loader(test_paths, test_labels, metadata=test_metadata, transform=val_transform, batch_size=batch_size, num_workers=num_workers) \n",
    "\n",
    "        # Training\n",
    "        n_classes = len(set(train_labels))\n",
    "        n_metadata = train_metadata.shape[1]\n",
    "\n",
    "        for model_name in model_names:\n",
    "\n",
    "            base_save_path = f'best_base_{model_name}_w_{fold}'\n",
    "            base_model     = BaseMetaModel(get_model(model_name, n_classes=n_classes, pretrained=True)).to(device)\n",
    "            base_model.load_state_dict(torch.load(os.path.join(saved_base_models_folder, base_save_path)))\n",
    "\n",
    "            for fusion_method in fusion_methods:\n",
    "                print(f'{\"*\"*89}\\n{model_name.upper()} {metacomb_name.upper()} FOLD {fold} {fusion_method.upper()}\\n{\"*\"*89}\\n')\n",
    "\n",
    "                save_path = f'{model_name}_{fusion_method}_{metacomb_name}_{fold}'\n",
    "                model     = MetaModel(base_model, n_classes, n_metadata=n_metadata, fusion_method=fusion_method, n_reducer_block=n_reducer_block).to(device)\n",
    "\n",
    "                optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "                scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=7)\n",
    "\n",
    "                train(model, train_dataloader, val_dataloader, optimizer, scheduler, criterion, device, n_epochs,\n",
    "                  saved_models_folder, saved_scores_folder, save_path, printfreq=10)\n",
    "\n",
    "                del model\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = ['vgg11', 'vit_b_32']\n",
    "model_names = ['vit_b_32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metacombs = [('age', 'gender', 'region')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************************************\n",
      "VIT_B_32 AGE_GENDER_REGION FOLD 0 CONCAT\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      1.1161       1.0959       0.6751      0.6853            1.0e-03       0.6\n",
      "    20      0.7629       0.9208       0.7496      0.6986     ***    1.0e-04       0.6\n",
      "    30      0.7515       0.9078       0.7522      0.7082            1.0e-04       0.6\n",
      "    40      0.7353       0.8867       0.7532      0.7135     ***    1.0e-04       0.6\n",
      "    50      0.7113       0.8846       0.7631      0.7171            1.0e-05       0.6\n",
      "    60      0.7140       0.8938       0.7696      0.7125            1.0e-05       0.6\n",
      "    70      0.7093       0.8960       0.7616      0.7147            1.0e-06       0.6\n",
      "    80      0.7101       0.8927       0.7651      0.7149            1.0e-07       0.6\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 80 Epochs: 45.0\n"
     ]
    }
   ],
   "source": [
    "#folds = [0, 1, 2, 3, 4]\n",
    "#folds = [1, 2, 3, 4]\n",
    "folds  = [0]\n",
    "n_reducer_block = 256\n",
    "\n",
    "for fold in folds:\n",
    "    for metacomb in metacombs:\n",
    "        metacomb_name = '_'.join(list(metacomb))\n",
    "        \n",
    "        metadata_cols = combcols_dict[metacomb]\n",
    "        \n",
    "         # Dataloaders\n",
    "        train_idcs = train_folds[fold]\n",
    "        val_idcs   = val_folds[fold]\n",
    "        train_imgs = df.loc[train_idcs, 'image'].values\n",
    "        val_imgs   = df.loc[val_idcs, 'image'].values\n",
    "        test_imgs  = df.loc[test_idcs, 'image'].values\n",
    "\n",
    "        train_paths = [f'{os.path.join(data_dir, img)}.jpg' for img in train_imgs]\n",
    "        val_paths   = [f'{os.path.join(data_dir, img)}.jpg' for img in val_imgs]\n",
    "        test_paths  = [f'{os.path.join(data_dir, img)}.jpg' for img in test_imgs]\n",
    "\n",
    "        train_labels = df.loc[train_idcs, 'diagnostic_number'].values\n",
    "        val_labels   = df.loc[val_idcs,   'diagnostic_number'].values\n",
    "        test_labels  = df.loc[test_idcs,  'diagnostic_number'].values\n",
    "\n",
    "        train_metadata = df.loc[train_idcs, metadata_cols].values\n",
    "        val_metadata   = df.loc[val_idcs, metadata_cols].values\n",
    "        test_metadata  = df.loc[test_idcs, metadata_cols].values\n",
    "        train_dataloader = get_data_loader(train_paths, train_labels, metadata=train_metadata, transform=train_transform, batch_size=batch_size, num_workers=num_workers)\n",
    "        val_dataloader   = get_data_loader(val_paths, val_labels, metadata=val_metadata, transform=val_transform, batch_size=batch_size, num_workers=num_workers)\n",
    "        test_dataloader  = get_data_loader(test_paths, test_labels, metadata=test_metadata, transform=val_transform, batch_size=batch_size, num_workers=num_workers) \n",
    "\n",
    "        # Training\n",
    "        n_classes = len(set(train_labels))\n",
    "        n_metadata = train_metadata.shape[1]\n",
    "\n",
    "        for model_name in model_names:\n",
    "\n",
    "            base_save_path = f'best_base_{model_name}_w_{fold}'\n",
    "            base_model     = BaseMetaModel(get_model(model_name, n_classes=n_classes, pretrained=True)).to(device)\n",
    "            base_model.load_state_dict(torch.load(os.path.join(saved_base_models_folder, base_save_path)))\n",
    "\n",
    "            for fusion_method in fusion_methods:\n",
    "                print(f'{\"*\"*89}\\n{model_name.upper()} {metacomb_name.upper()} FOLD {fold} {fusion_method.upper()}\\n{\"*\"*89}\\n')\n",
    "\n",
    "                save_path = f'{model_name}_{fusion_method}_{metacomb_name}_{fold}'\n",
    "                model     = MetaModel(base_model, n_classes, n_metadata=n_metadata, fusion_method=fusion_method, n_reducer_block=n_reducer_block).to(device)\n",
    "\n",
    "                optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "                scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=7)\n",
    "\n",
    "                train(model, train_dataloader, val_dataloader, optimizer, scheduler, criterion, device, n_epochs,\n",
    "                  saved_models_folder, saved_scores_folder, save_path, printfreq=10)\n",
    "\n",
    "                del model\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba metablock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************************************\n",
      "RESNET18 AGE FOLD 0 METABLOCK\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      1.2209       1.1053       0.6307      0.6921     ***    1.0e-03       0.5\n",
      "    20      1.1470       1.0794       0.6484      0.6923            1.0e-03       0.5\n",
      "    30      1.0892       1.0071       0.6655      0.7043            1.0e-03       0.5\n",
      "    40      1.0064       0.9626       0.6911      0.7108            1.0e-04       0.5\n",
      "    50      0.9863       0.9507       0.7001      0.7099            1.0e-05       0.5\n",
      "    60      0.9864       0.9578       0.6979      0.6988            1.0e-06       0.5\n",
      "Training stopped early\n",
      "-----------------------------------------------------------------------------------------\n",
      "Total time [min] for 63 Epochs: 31.9\n",
      "*****************************************************************************************\n",
      "RESNET18 GENDER FOLD 0 METABLOCK\n",
      "*****************************************************************************************\n",
      "\n",
      " Epoch    Train Loss    Val Loss    Train Acc    Val Acc    Best      lr      Time [min]\n",
      "-----------------------------------------------------------------------------------------\n",
      "    10      1.1955       1.0855       0.6230      0.6820     ***    1.0e-03       0.5\n",
      "    20      1.1304       1.0384       0.6448      0.6861            1.0e-03       0.5\n",
      "    30      1.0860       1.0190       0.6624      0.6964            1.0e-03       0.5\n",
      "    40      1.0718       0.9875       0.6628      0.6892            1.0e-03       0.5\n"
     ]
    }
   ],
   "source": [
    "#folds = [0, 1, 2, 3, 4]\n",
    "#folds = [1, 2, 3, 4]\n",
    "fusion_methods = ['metablock']\n",
    "folds  = [0]\n",
    "n_reducer_block = 256\n",
    "\n",
    "for fold in folds:\n",
    "    for metacomb in metacombs:\n",
    "        metacomb_name = '_'.join(list(metacomb))\n",
    "        \n",
    "        metadata_cols = combcols_dict[metacomb]\n",
    "        \n",
    "         # Dataloaders\n",
    "        train_idcs = train_folds[fold]\n",
    "        val_idcs   = val_folds[fold]\n",
    "        train_imgs = df.loc[train_idcs, 'image'].values\n",
    "        val_imgs   = df.loc[val_idcs, 'image'].values\n",
    "        test_imgs  = df.loc[test_idcs, 'image'].values\n",
    "\n",
    "        train_paths = [f'{os.path.join(data_dir, img)}.jpg' for img in train_imgs]\n",
    "        val_paths   = [f'{os.path.join(data_dir, img)}.jpg' for img in val_imgs]\n",
    "        test_paths  = [f'{os.path.join(data_dir, img)}.jpg' for img in test_imgs]\n",
    "\n",
    "        train_labels = df.loc[train_idcs, 'diagnostic_number'].values\n",
    "        val_labels   = df.loc[val_idcs,   'diagnostic_number'].values\n",
    "        test_labels  = df.loc[test_idcs,  'diagnostic_number'].values\n",
    "\n",
    "        train_metadata = df.loc[train_idcs, metadata_cols].values\n",
    "        val_metadata   = df.loc[val_idcs, metadata_cols].values\n",
    "        test_metadata  = df.loc[test_idcs, metadata_cols].values\n",
    "        train_dataloader = get_data_loader(train_paths, train_labels, metadata=train_metadata, transform=train_transform, batch_size=batch_size, num_workers=num_workers)\n",
    "        val_dataloader   = get_data_loader(val_paths, val_labels, metadata=val_metadata, transform=val_transform, batch_size=batch_size, num_workers=num_workers)\n",
    "        test_dataloader  = get_data_loader(test_paths, test_labels, metadata=test_metadata, transform=val_transform, batch_size=batch_size, num_workers=num_workers) \n",
    "\n",
    "        # Training\n",
    "        n_classes = len(set(train_labels))\n",
    "        n_metadata = train_metadata.shape[1]\n",
    "        \n",
    "        for model_name in model_names:\n",
    "\n",
    "            base_save_path = f'best_base_{model_name}_w_{fold}'\n",
    "            base_model     = BaseMetaModel(get_model(model_name, n_classes=n_classes, pretrained=True)).to(device)\n",
    "            base_model.load_state_dict(torch.load(os.path.join(saved_base_models_folder, base_save_path)))\n",
    "\n",
    "            for fusion_method in fusion_methods:\n",
    "                print(f'{\"*\"*89}\\n{model_name.upper()} {metacomb_name.upper()} FOLD {fold} {fusion_method.upper()}\\n{\"*\"*89}\\n')\n",
    "\n",
    "                save_path = f'{model_name}_{fusion_method}_{metacomb_name}_{fold}'\n",
    "                model     = MetaModel(base_model, n_classes, n_metadata=n_metadata, fusion_method=fusion_method, n_reducer_block=n_reducer_block).to(device)\n",
    "\n",
    "                optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "                scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=7)\n",
    "\n",
    "                train(model, train_dataloader, val_dataloader, optimizer, scheduler, criterion, device, n_epochs,\n",
    "                  saved_models_folder, saved_scores_folder, save_path, printfreq=10)\n",
    "\n",
    "                del model\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir('imgs/ISIC_2019_Training_Input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['concat']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds            = [0]\n",
    "model_names = ['resnet18', 'resnet50', 'effnetb3', 'resnext50', 'vgg11', 'vit_b_32']\n",
    "# model_names      = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'effnetb0', 'effnetb1',\n",
    "#                'effnetb2', 'effnetb3', 'effnetb4', 'effnetb5']\n",
    "#fusion_methods   = ['concat', 'metanet', 'metablock']\n",
    "fusion_methods   = ['concat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age',),\n",
       " ('gender',),\n",
       " ('region',),\n",
       " ('age', 'gender'),\n",
       " ('age', 'region'),\n",
       " ('gender', 'region'),\n",
       " ('age', 'gender', 'region')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usemeta = ['age', 'gender', 'region']\n",
    "metacombs = get_combs(usemeta)\n",
    "metacombs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNET18 AGE FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNET50 AGE FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n",
      "*******************************************************************************\n",
      "EFFNETB3 AGE FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNEXT50 AGE FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "VGG11 AGE FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "VIT_B_32 AGE FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNET18 GENDER FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNET50 GENDER FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n",
      "*******************************************************************************\n",
      "EFFNETB3 GENDER FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNEXT50 GENDER FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "VGG11 GENDER FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "VIT_B_32 GENDER FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNET18 REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNET50 REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n",
      "*******************************************************************************\n",
      "EFFNETB3 REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNEXT50 REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "VGG11 REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "VIT_B_32 REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNET18 AGE_GENDER FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNET50 AGE_GENDER FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n",
      "*******************************************************************************\n",
      "EFFNETB3 AGE_GENDER FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNEXT50 AGE_GENDER FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "VGG11 AGE_GENDER FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "VIT_B_32 AGE_GENDER FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNET18 AGE_REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNET50 AGE_REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n",
      "*******************************************************************************\n",
      "EFFNETB3 AGE_REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNEXT50 AGE_REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "VGG11 AGE_REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "VIT_B_32 AGE_REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNET18 GENDER_REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNET50 GENDER_REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n",
      "*******************************************************************************\n",
      "EFFNETB3 GENDER_REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNEXT50 GENDER_REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "VGG11 GENDER_REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "VIT_B_32 GENDER_REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNET18 AGE_GENDER_REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNET50 AGE_GENDER_REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n",
      "*******************************************************************************\n",
      "EFFNETB3 AGE_GENDER_REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "RESNEXT50 AGE_GENDER_REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "VGG11 AGE_GENDER_REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "VIT_B_32 AGE_GENDER_REGION FOLD 0 CONCAT\n",
      "*******************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/skin/ISIC2019/../utils/metrics.py:47: UserWarning: An output with one or more elements was resized since it had shape [4968, 6], which does not match the required output shape [4968, 8]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:17.)\n",
      "  torch.cat(prob_list, out=y_prob)\n"
     ]
    }
   ],
   "source": [
    "#folds = [0, 1, 2, 3, 4]\n",
    "#folds = [1, 2, 3, 4]\n",
    "folds  = [0]\n",
    "n_reducer_block = 256\n",
    "\n",
    "n_classes = 8\n",
    "\n",
    "all_metrics_dict = dict()\n",
    "for fold in folds:\n",
    "    fold_dict = dict()\n",
    "    for metacomb in metacombs:\n",
    "        metacomb_dict = dict()\n",
    "        metacomb_name = '_'.join(list(metacomb))\n",
    "        \n",
    "        metadata_cols = combcols_dict[metacomb]\n",
    "        \n",
    "         # Dataloaders\n",
    "        test_imgs  = df.loc[test_idcs, 'image'].values\n",
    "\n",
    "        test_paths  = [f'{os.path.join(data_dir, img)}.jpg' for img in test_imgs]\n",
    "\n",
    "        test_labels  = df.loc[test_idcs,  'diagnostic_number'].values\n",
    "\n",
    "        test_metadata  = df.loc[test_idcs, metadata_cols].values\n",
    "        test_dataloader  = get_data_loader(test_paths, test_labels, metadata=test_metadata, transform=val_transform, batch_size=batch_size, num_workers=num_workers) \n",
    "\n",
    "        # Training\n",
    "        n_metadata = test_metadata.shape[1]\n",
    "        \n",
    "\n",
    "        for model_name in model_names:\n",
    "            model_dict = dict()\n",
    "            base_model     = BaseMetaModel(get_model(model_name, n_classes=n_classes, pretrained=True)).to(device)\n",
    "\n",
    "            for fusion_method in fusion_methods:\n",
    "                print(f'{\"*\"*79}\\n{model_name.upper()} {metacomb_name.upper()} FOLD {fold} {fusion_method.upper()}\\n{\"*\"*79}\\n')\n",
    "                \n",
    "                save_path = f'best_{model_name}_{fusion_method}_{metacomb_name}_{fold}'\n",
    "                \n",
    "                model = MetaModel(base_model, n_classes, n_metadata=n_metadata, fusion_method=fusion_method, n_reducer_block=n_reducer_block).to(device)\n",
    "                model.load_state_dict(torch.load(os.path.join(saved_models_folder, save_path)))\n",
    "\n",
    "                y_true, y_prob, y_pred = get_scores(model, test_dataloader, batch_size, device)\n",
    "                np.save(f'test_scores/y_true_{model_name}_{fusion_method}_{metacomb_name}_{fold}', y_true)\n",
    "                np.save(f'test_scores/y_prob_{model_name}_{fusion_method}_{metacomb_name}_{fold}', y_prob)\n",
    "                np.save(f'test_scores/y_pred_{model_name}_{fusion_method}_{metacomb_name}_{fold}', y_pred)\n",
    "                \n",
    "                metrics_dict = get_metrics(y_true, y_prob, y_pred)\n",
    "                \n",
    "                del model\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                model_dict[fusion_method] = metrics_dict\n",
    "            metacomb_dict[model_name] = model_dict\n",
    "        fold_dict[metacomb_name] = metacomb_dict\n",
    "    all_metrics_dict[fold] = fold_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gabriel/skin/ISIC2019/test_scores.zip'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.make_archive('test_scores', 'zip', 'test_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #folds = [0, 1, 2, 3, 4]\n",
    "# #folds = [1, 2, 3, 4]\n",
    "# folds  = [0]\n",
    "# n_reducer_block = 256\n",
    "\n",
    "# all_metrics_dict = dict()\n",
    "# for fold in folds:\n",
    "#     fold_dict = dict()\n",
    "#     for metacomb in metacombs:\n",
    "#         metacomb_name = '_'.join(list(metacomb))\n",
    "        \n",
    "#         metadata_cols = combcols_dict[metacomb]\n",
    "        \n",
    "#          # Dataloaders\n",
    "#         test_imgs  = df.loc[test_idcs, 'image'].values\n",
    "\n",
    "#         test_paths  = [f'{os.path.join(data_dir, img)}.jpg' for img in test_imgs]\n",
    "\n",
    "#         test_labels  = df.loc[test_idcs,  'diagnostic_number'].values\n",
    "\n",
    "#         test_metadata  = df.loc[test_idcs, metadata_cols].values\n",
    "#         test_dataloader  = get_data_loader(test_paths, test_labels, metadata=test_metadata, transform=val_transform, batch_size=batch_size, num_workers=num_workers) \n",
    "\n",
    "#         # Training\n",
    "#         n_classes = len(set(train_labels))\n",
    "#         n_metadata = test_metadata.shape[1]\n",
    "\n",
    "#         for model_name in model_names:\n",
    "#             model_dict = dict()\n",
    "#             base_model     = BaseMetaModel(get_model(model_name, n_classes=n_classes, pretrained=True)).to(device)\n",
    "\n",
    "#             for fusion_method in fusion_methods:\n",
    "#                 print(f'{\"*\"*79}\\n{model_name.upper()} {metacomb_name.upper()} FOLD {fold} {fusion_method.upper()}\\n{\"*\"*79}\\n')\n",
    "                \n",
    "#                 save_path = f'best_{model_name}_{fusion_method}_{metacomb_name}_{fold}'\n",
    "#                 #print(save_path, n_metadata)\n",
    "                \n",
    "#                 model = MetaModel(base_model, n_classes, n_metadata=n_metadata, fusion_method=fusion_method, n_reducer_block=n_reducer_block).to(device)\n",
    "#                 model.load_state_dict(torch.load(os.path.join(saved_models_folder, save_path)))\n",
    "\n",
    "#                 y_true, y_prob, y_pred = get_scores(model, test_dataloader, batch_size, device)\n",
    "#                 metrics_dict = get_metrics(y_true, y_prob, y_pred)\n",
    "                \n",
    "#                 del model\n",
    "#                 gc.collect()\n",
    "#                 torch.cuda.empty_cache()\n",
    "                \n",
    "#                 model_dict[fusion_method] = metrics_dict\n",
    "#             metacomb_dict[model_name] = model_dict\n",
    "#         fold_dict[metacomb_name] = metacomb_dict\n",
    "#     all_metrics_dict[fold] = fold_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('metrics_combs_allmodels_concat.json', 'w') as outfile:\n",
    "    json.dump(all_metrics_dict, outfile)\n",
    "    \n",
    "all_metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.730676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.929802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.520147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.725528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.724709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.730676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>4968.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        concat\n",
       "accuracy              0.730676\n",
       "auc                   0.929802\n",
       "balanced_accuracy     0.520147\n",
       "f1-score              0.725528\n",
       "precision             0.724709\n",
       "recall                0.730676\n",
       "support            4968.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_metrics_dict[0]['age']['resnet18'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'gender',\n",
       " 'region',\n",
       " 'age_gender',\n",
       " 'age_region',\n",
       " 'gender_region',\n",
       " 'age_gender_region']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metacomb_names = ['_'.join(list(metacomb)) for metacomb in metacombs]\n",
    "metacomb_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>age_gender</th>\n",
       "      <th>age_region</th>\n",
       "      <th>gender_region</th>\n",
       "      <th>age_gender_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.716968</td>\n",
       "      <td>0.695939</td>\n",
       "      <td>0.711760</td>\n",
       "      <td>0.720001</td>\n",
       "      <td>0.724570</td>\n",
       "      <td>0.690627</td>\n",
       "      <td>0.724266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.707729</td>\n",
       "      <td>0.716586</td>\n",
       "      <td>0.726651</td>\n",
       "      <td>0.730878</td>\n",
       "      <td>0.705113</td>\n",
       "      <td>0.730676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.719229</td>\n",
       "      <td>0.700178</td>\n",
       "      <td>0.712359</td>\n",
       "      <td>0.721029</td>\n",
       "      <td>0.725764</td>\n",
       "      <td>0.694337</td>\n",
       "      <td>0.725577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "      <td>4968.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.707729</td>\n",
       "      <td>0.716586</td>\n",
       "      <td>0.726651</td>\n",
       "      <td>0.730878</td>\n",
       "      <td>0.705113</td>\n",
       "      <td>0.730676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.511740</td>\n",
       "      <td>0.478285</td>\n",
       "      <td>0.520425</td>\n",
       "      <td>0.506165</td>\n",
       "      <td>0.517731</td>\n",
       "      <td>0.476470</td>\n",
       "      <td>0.527001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.926833</td>\n",
       "      <td>0.917472</td>\n",
       "      <td>0.920209</td>\n",
       "      <td>0.927797</td>\n",
       "      <td>0.929533</td>\n",
       "      <td>0.914203</td>\n",
       "      <td>0.929182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           age       gender       region   age_gender  \\\n",
       "precision             0.716968     0.695939     0.711760     0.720001   \n",
       "recall                0.724638     0.707729     0.716586     0.726651   \n",
       "f1-score              0.719229     0.700178     0.712359     0.721029   \n",
       "support            4968.000000  4968.000000  4968.000000  4968.000000   \n",
       "accuracy              0.724638     0.707729     0.716586     0.726651   \n",
       "balanced_accuracy     0.511740     0.478285     0.520425     0.506165   \n",
       "auc                   0.926833     0.917472     0.920209     0.927797   \n",
       "\n",
       "                    age_region  gender_region  age_gender_region  \n",
       "precision             0.724570       0.690627           0.724266  \n",
       "recall                0.730878       0.705113           0.730676  \n",
       "f1-score              0.725764       0.694337           0.725577  \n",
       "support            4968.000000    4968.000000        4968.000000  \n",
       "accuracy              0.730878       0.705113           0.730676  \n",
       "balanced_accuracy     0.517731       0.476470           0.527001  \n",
       "auc                   0.929533       0.914203           0.929182  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({metacomb: all_metrics_dict[0][metacomb]['resnet18']['concat'] for metacomb in metacomb_names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({metacomb: all_metrics_dict[0][metacomb]['resnet18']['metanet'] for metacomb in metacomb_names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({metacomb: all_metrics_dict[0][metacomb]['resnet18']['metablock'] for metacomb in metacomb_names})"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "055184640ce34877a71c8f514a57365b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "23c4b9c3e8714931aa355dfd0ef250b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_446acd5b23ab4c1aae4b34ffdc0e3e03",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6ee31b43c638445dbd33ea9e4f9c2818",
      "value": "100%"
     }
    },
    "263fffa53b4e4e1db56db6e6a95b2f9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4db7d742a5d4367822911b22b554e22",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_055184640ce34877a71c8f514a57365b",
      "value": " 171M/171M [00:02&lt;00:00, 77.8MB/s]"
     }
    },
    "29a8b74c017b4c3d8d459537b3f4ba28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2e7ce0981788482794edabcf158c486c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a30d4b695114b098ffe71d63ba67e13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4162fdbe4e244d93b2c554f5a826bf03",
      "max": 87319819,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef54030eed4f4c64b73b57cbb245a856",
      "value": 87319819
     }
    },
    "3d4f8a3b3db24d96b5435f2455ca521f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfe55772269343bc9a18666b40407c1f",
      "max": 241627721,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4904a282e52b497fa4ae68be163457f5",
      "value": 241627721
     }
    },
    "3d7903a3643c418d9f08fbd9dba49421": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4285db382984092aa19d846fd433bdb",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_29a8b74c017b4c3d8d459537b3f4ba28",
      "value": " 230M/230M [00:02&lt;00:00, 97.2MB/s]"
     }
    },
    "4162fdbe4e244d93b2c554f5a826bf03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "446acd5b23ab4c1aae4b34ffdc0e3e03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47e84faa262e49fd850f7a42211d67e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4904a282e52b497fa4ae68be163457f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5fd4701d24d941eabf64fca7c4b7f3e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e7ce0981788482794edabcf158c486c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_47e84faa262e49fd850f7a42211d67e0",
      "value": " 83.3M/83.3M [00:01&lt;00:00, 26.4MB/s]"
     }
    },
    "60341d0da36144b7b912538d3b83d424": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_75383e93d2f14949b86aa86a58819dbe",
       "IPY_MODEL_88e1445d3c86459e89065742da786c8e",
       "IPY_MODEL_263fffa53b4e4e1db56db6e6a95b2f9a"
      ],
      "layout": "IPY_MODEL_62ca065bac1141f382476f056b7517d7"
     }
    },
    "6041b410039d453782ea8eef11374dac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62ca065bac1141f382476f056b7517d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ee31b43c638445dbd33ea9e4f9c2818": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f9d1f63539c4776b64b3eb15fd990e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75383e93d2f14949b86aa86a58819dbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6041b410039d453782ea8eef11374dac",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c97cd868c68744ec8267be865bc6a188",
      "value": "100%"
     }
    },
    "88e1445d3c86459e89065742da786c8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8ae428e69884b1287b1d26f1afd7b4d",
      "max": 178793939,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a2d81c967de949838b25ff86b86a221f",
      "value": 178793939
     }
    },
    "96e19af9fd894a04aa316146b017504a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c60932b2d049458983764dc956aab433",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6f9d1f63539c4776b64b3eb15fd990e6",
      "value": "100%"
     }
    },
    "9e907133a5c54a22854c6f426a695b45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_96e19af9fd894a04aa316146b017504a",
       "IPY_MODEL_3d4f8a3b3db24d96b5435f2455ca521f",
       "IPY_MODEL_3d7903a3643c418d9f08fbd9dba49421"
      ],
      "layout": "IPY_MODEL_bc3afd22181e4185b6d49d3b8fbc5238"
     }
    },
    "a2d81c967de949838b25ff86b86a221f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a5279ae92567467dac9c5c21fdb226d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_23c4b9c3e8714931aa355dfd0ef250b5",
       "IPY_MODEL_3a30d4b695114b098ffe71d63ba67e13",
       "IPY_MODEL_5fd4701d24d941eabf64fca7c4b7f3e8"
      ],
      "layout": "IPY_MODEL_cf35b6c2f49045ef8dbb4df29e898a95"
     }
    },
    "bc3afd22181e4185b6d49d3b8fbc5238": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4285db382984092aa19d846fd433bdb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c60932b2d049458983764dc956aab433": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c97cd868c68744ec8267be865bc6a188": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf35b6c2f49045ef8dbb4df29e898a95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfe55772269343bc9a18666b40407c1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef54030eed4f4c64b73b57cbb245a856": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f4db7d742a5d4367822911b22b554e22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8ae428e69884b1287b1d26f1afd7b4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
